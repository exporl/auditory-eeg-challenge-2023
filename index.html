<!DOCTYPE HTML>
<html lang="en">
    <head>
	<meta name="generator" content="Hugo 0.103.1" />

<title>ICASSP 2023: Auditory EEG challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="/auditory-eeg-challenge-2023/style.css" />
<meta property="og:title" content="Home" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://exporl.github.io/auditory-eeg-challenge-2023/" />

</head>
    <body class="is-preload">
        <div id="page-wrapper"><div id="header">
    <h1><a href="https://exporl.github.io/auditory-eeg-challenge-2023/" id="logo">
        Auditory EEG Challenge - ICASSP 2023
    </a></h1>

    <nav id="nav">
        <ul>
                <li class="current">
                    <a href="/auditory-eeg-challenge-2023/">Home</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2023/dataset/">Dataset</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2023/registration/">Registration</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2023/task1/">Task 1: Match-mismatch</a>
                <li class="">
                    <a href="/auditory-eeg-challenge-2023/task2/">Task 2: Regression</a>
        </ul>
    </nav>
</div>
<section class="wrapper style2">
    <div class="container">
        <header class="major">
            <h2>Auditory EEG decoding challenge</h2><p>This challenge focuses on establishing a relationship between measured brain activity (EEG) and an auditory stimulus</p>
        </header>
    </div>
</section>
<section class="wrapper style1">
    <div class="container">
        
            <div class=""><h2 id="challenge-call">Challenge Call</h2>
<p>Various neuroimaging techniques can be used to investigate how the brain processes sound.
Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal
resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the
brain are also helpful in detecting or diagnosing potential hearing loss. They enable differential diagnosis of
populations that can otherwise not be tested, such as young children or people with mental disabilities. In
addition, there is a growing field of research in which auditory attention is decoded from the brain, with
potential applications in smart hearing aids.
An increasingly popular method in these fields is to relate a person&rsquo;s electroencephalogram (EEG) to a
feature of the natural speech signal they were listening to. This is typically done using linear regression
to predict the EEG signal from the stimulus or to decode the stimulus from the EEG. Given the very low
signal-to-noise ratio of the EEG, this is a challenging problem, and several non-linear methods have been
proposed to improve upon the linear regression methods.
In the Auditory-EEG challenge, teams will compete to build the best model to relate speech to EEG. We
provide a large auditory EEG dataset containing data from 85 subjects who listen on average to 108 minutes
of single-speaker stimuli for a total of 157 hours of data. We define two tasks:</p>
<p><strong>Task 1 match-mismatch</strong>: given two segments of speech and a segment of EEG, which segment of speech
matches the EEG?</p>
<p><strong>Task 2 regression</strong>: reconstruct the speech envelope from the EEG.
We provide the dataset, code for preprocessing the EEG and for creating commonly used stimulus
representations, and two baseline methods.</p>
<p>Teams can register by sending a mail to
<a href="auditoryeegchallenge@kuleuven.be">auditoryeegchallenge@kuleuven.be</a> with the names of the team members, emails, and affiliations.
The intellectual property (IP) is not transferred to the challenge organizers, i.e. if the code is shared/submitted, the participants remain
the owners of their code.</p>
</div>
            <div class=""><h2 id="get-started">Get started</h2>
<ol>
<li>
<p>Send a mail to <a href="auditoryeegchallenge@kuleuven.be">auditoryeegchallenge@kuleuven.be</a> with the names of the team members, emails, and affiliations. You will receive a password to download the data</p>
</li>
<li>
<p>Download the data from <a href="https://kuleuven-my.sharepoint.com/:f:/g/personal/lies_bollens_kuleuven_be/EkaIjOmoPIRHmYLdLK8b2VQBY_2ouqNSnHHTHyRl3Zn-2w?e=KhX7d0">ICASSP-2023-eeg-decoding-challenge-dataset</a></p>
<ul>
<li><strong>split_data(.zip)</strong> contains already preprocessed, split and normalized data; ready for model training/evaluation. If you want to get started quickly, you can opt to only download this folder/zipfile.</li>
<li><strong>preprocessed_eeg(.zip)</strong> and <strong>preprocessed_stimuli(.zip)</strong> contain preprocessed EEG and stimuli files (envelope and mel features) respectively. At this stage data is not yet split into different sets and normalized. To go from this to the data in split_data, you will have to run run_splitting_and_normalization.py.</li>
<li><strong>raw_eeg(_x.zip)</strong> and <strong>stimuli(.zip)</strong> contain the raw EEG and stimuli files. If you want to process the stimuli files, you can run run_preprocessing.py. The processed stimuli files will be stored in the processed_stimuli. Currently, no preprocessing code is made available to preprocess EEG, so you will have to write your own implementation or use the precomputed processed_eeg folder.</li>
</ul>
</li>
<li>
<p>Clone the starting code from our <a href="https://github.com/exporl/auditory-eeg-challenge-2023-code">github repository</a> and get started.
The repository contains preprocessing code, as well as baseline models for each of the tasks.</p>
</li>
</ol>
</div>
            <div class=""><h2 id="timeline">Timeline</h2>
<ul>
<li>November 21, 2022: Registration opens</li>
<li>November 21, 2022: Release of training set, code, baseline methods and documentation</li>
<li>January 6, 2023: Release of evaluation test set</li>
<li>February 6, 2023: Deadline for submitting results for both tasks</li>
<li>February 20, 2023: ICASSP 2023 grand challenge 2-page paper deadline (top 5 teams only)</li>
<li>March 7, 2023: ICASSP 2023 grand challenge 2-page paper acceptance notification</li>
<li>March 14, 2023: ICASSP 2023 grand challenge 2-page camera-ready deadline</li>
<li>June 4-8, 2023: ICASSP 2023 conference</li>
<li>August 9, 2023: IEEE open journal of signal processing grand challenge papers deadline</li>
</ul>
</div>
    </div>
</section>
<section id="cta" class="wrapper style3">
    <div class="container">
        <header>
            <h2>Are you ready?</h2>
                <a href="task1" class="button">Get started with task 1</a>
        </header>
    </div>
</section>
<div id="footer">
    <div class="container">
        <div class="row">
        </div>
    </div>

    <ul class="icons">
    </ul>

    <div class="copyright">
        <ul class="menu">
            
                <li>Design: <a href="https://html5up.net">HTML5 UP</a>
                <li><a href="https://github.com/half-duplex/hugo-arcana">Theme</a>
        </ul>
    </div>
</div>
</div><script src="/auditory-eeg-challenge-2023/js/jquery.min.js"></script>
<script src="/auditory-eeg-challenge-2023/js/jquery.dropotron.min.js"></script>
<script src="/auditory-eeg-challenge-2023/js/browser.min.js"></script>
<script src="/auditory-eeg-challenge-2023/js/breakpoints.min.js"></script>
<script src="/auditory-eeg-challenge-2023/js/util.js"></script>
<script src="/auditory-eeg-challenge-2023/js/main.js"></script>
</body>
</html>

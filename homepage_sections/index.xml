<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage_sections on ICASSP 2023: Auditory EEG challenge</title>
    <link>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/</link>
    <description>Recent content in Homepage_sections on ICASSP 2023: Auditory EEG challenge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General description</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/general_description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/general_description/</guid>
      <description>Challenge Call Various neuroimaging techniques can be used to investigate how the brain processes sound. Electroencephalography (EEG) is popular because it is relatively easy to conduct and has a high temporal resolution. Besides fundamental neuroscience research, EEG-based measures of auditory processing in the brain are also helpful in detecting or diagnosing potential hearing loss. They enable differential diagnosis of populations that can otherwise not be tested, such as young children or people with mental disabilities.</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/timeline/</guid>
      <description>Timeline (anywhere on earth) November 21, 2022: Registration opens November 21, 2022: Release of training set, code, baseline methods and documentation January 6, 2023: Release of evaluation test set February 6, 2023: Deadline for submitting results for both tasks February 20, 2023: ICASSP 2023 grand challenge 2-page paper deadline (top 5 teams only) March 7, 2023: ICASSP 2023 grand challenge 2-page paper acceptance notification March 14, 2023: ICASSP 2023 grand challenge 2-page camera-ready deadline June 4-8, 2023: ICASSP 2023 conference August 9, 2023: IEEE open journal of signal processing grand challenge papers deadline </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/organizers/</guid>
      <description>Organizers Mohammad Jalilpour Monesi 1, 2 (mohammad.jalilpourmonesi@esat.kuleuven.be)
Lies Bollens 1, 2 (lies.bollens@esat.kuleuven.be)
Bernd Accou 1, 2
Hugo Van hamme 1
Tom Francart 2
KU Leuven, PSI, Dept. of Electrical engineering (ESAT), Leuven, Belgium
KU Leuven, ExpORL, Dept. Neurosciences, Leuven, Belgium</description>
    </item>
    
    <item>
      <title>Get started</title>
      <link>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/leaderboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://exporl.github.io/auditory-eeg-challenge-2023/homepage_sections/leaderboard/</guid>
      <description>Get started Send a mail to auditoryeegchallenge@kuleuven.be with the names of the team members, emails, and affiliations. You will receive a password to download the data
Download the data from ICASSP-2023-eeg-decoding-challenge-dataset
split_data(.zip) contains already preprocessed, split and normalized data; ready for model training/evaluation. If you want to get started quickly, you can opt to only download this folder/zipfile. preprocessed_eeg(.zip) and preprocessed_stimuli(.zip) contain preprocessed EEG and stimuli files ( speech envelope and mel spectrogram features) respectively.</description>
    </item>
    
  </channel>
</rss>
